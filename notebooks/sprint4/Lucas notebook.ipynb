{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Instalação de Dependências "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZWJbEoKq1gu",
        "outputId": "e8bbcf05-926f-436a-ff8f-ec684c1a6a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/user/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/user/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "  Downloading pyarrow-17.0.0-cp311-cp311-macosx_10_15_x86_64.whl (29.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp311-cp311-macosx_10_9_universal2.whl (910 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.1/910.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyarrow) (2.1.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastparquet) (2.2.3)\n",
            "Collecting cramjam>=2.3\n",
            "  Downloading cramjam-2.8.4-cp311-cp311-macosx_10_12_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /Users/user/Library/Python/3.11/lib/python/site-packages (from fastparquet) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/user/Library/Python/3.11/lib/python/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/user/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: pyarrow, fsspec, cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.4 fastparquet-2024.5.0 fsspec-2024.9.0 pyarrow-17.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyarrow fastparquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTtRIX_16BtC"
      },
      "source": [
        "# Tratamento e Ajustes nos dados de resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RESULTADOS 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nas células a seguir foram selecionadas as colunas necessarias para o desenvolvimento desse modelo e o tratamento para que não existam dados duplicados. Por fim, foi gerado um novo dataset utilizando parquet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'RESULTADOS_02_03_2024.xlsx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_result02 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRESULTADOS_02_03_2024.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RESULTADOS_02_03_2024.xlsx'"
          ]
        }
      ],
      "source": [
        "df_result02 = pd.read_excel('RESULTADOS_02_03_2024.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_result02.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.columns = df_result02.iloc[0]\n",
        "df_result02 = df_result02[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_result02.columns = df_result02.columns.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = df_result02.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar todas as duplicatas\n",
        "duplicates = df_result02[df_result02.duplicated(keep=False)]\n",
        "\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = df_result02.drop_duplicates()\n",
        "df_result02.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.to_parquet('df_result02.parquet', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = pd.read_parquet('df_result02.parquet')\n",
        "df_result02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = df_result02.loc[:, df_result02.columns != 'nan']\n",
        "df_result02 = df_result02.loc[:, df_result02.columns != 'ID']\n",
        "df_result02 = df_result02.loc[:, df_result02.columns != 'STATUS']\n",
        "df_result02\n",
        "\n",
        "#remover colunas inuteis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_unicos = df_result02['NAME'].nunique()\n",
        "print(f\"A coluna 'NAME' possui {num_unicos} valores únicos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valores_unicos = df_result02['NAME'].unique()\n",
        "print(\"Valores únicos na coluna 'NAME':\")\n",
        "print(valores_unicos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frequencia = df_result02['NAME'].value_counts()\n",
        "print(\"Frequência de cada valor único na coluna 'NAME':\")\n",
        "print(frequencia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explorando Value_id e Name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupar por 'NAME' e calcular estatísticas descritivas de 'VALUE_ID'\n",
        "estatisticas = df_result02.groupby('NAME')['VALUE_ID'].describe()\n",
        "print(estatisticas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='NAME', y='VALUE_ID', data=df_result02)\n",
        "plt.title('Distribuição de VALUE_ID por NAME')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "medias = df_result02.groupby('NAME')['VALUE_ID'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='NAME', y='VALUE_ID', data=medias)\n",
        "plt.title('Média de VALUE_ID por NAME')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar lista de valores de 'VALUE_ID' para cada grupo de 'NAME'\n",
        "grupos = [grupo['VALUE_ID'].dropna().values for nome, grupo in df_result02.groupby('NAME')]\n",
        "\n",
        "# Realizar o teste ANOVA\n",
        "estatistica, p_valor = f_oneway(*grupos)\n",
        "print(f'Estatística F: {estatistica}')\n",
        "print(f'Valor-p: {p_valor}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explorando Unity, Value e ValueID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar os tipos de dados\n",
        "print(df_result02[['UNIT', 'VALUE', 'VALUE_ID']].dtypes)\n",
        "\n",
        "# Converter 'VALUE' e 'VALUE_ID' para numérico, se necessário\n",
        "df_result02['VALUE'] = pd.to_numeric(df_result02['VALUE'], errors='coerce')\n",
        "df_result02['VALUE_ID'] = pd.to_numeric(df_result02['VALUE_ID'], errors='coerce')\n",
        "\n",
        "# Remover valores nulos nas colunas de interesse\n",
        "df_result02 = df_result02.dropna(subset=['UNIT', 'VALUE', 'VALUE_ID'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estatísticas descritivas de 'VALUE'\n",
        "print(\"Estatísticas de 'VALUE':\")\n",
        "print(df_result02['VALUE'].describe())\n",
        "\n",
        "# Estatísticas descritivas de 'VALUE_ID'\n",
        "print(\"\\nEstatísticas de 'VALUE_ID':\")\n",
        "print(df_result02['VALUE_ID'].describe())\n",
        "\n",
        "# Valores únicos em 'UNIT'\n",
        "print(\"\\nValores únicos em 'UNIT':\")\n",
        "print(df_result02['UNIT'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_result02['VALUE_ID'], df_result02['VALUE'], alpha=0.5)\n",
        "plt.title('Relação entre VALUE_ID e VALUE')\n",
        "plt.xlabel('VALUE_ID')\n",
        "plt.ylabel('VALUE')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "df_result02.boxplot(column='VALUE', by='UNIT', grid=False)\n",
        "plt.title('Distribuição de VALUE por UNIT')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('UNIT')\n",
        "plt.ylabel('VALUE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograma de VALUE\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(df_result02['VALUE'], bins=30, alpha=0.7)\n",
        "plt.title('Distribuição de VALUE')\n",
        "plt.xlabel('VALUE')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n",
        "\n",
        "# Histograma de VALUE_ID\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(df_result02['VALUE_ID'], bins=30, alpha=0.7, color='orange')\n",
        "plt.title('Distribuição de VALUE_ID')\n",
        "plt.xlabel('VALUE_ID')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Matriz de correlação\n",
        "corr = df_result02[['VALUE', 'VALUE_ID']].corr()\n",
        "print(\"Matriz de correlação:\")\n",
        "print(corr)\n",
        "\n",
        "# Heatmap da correlação\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlação entre VALUE e VALUE_ID')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agrupamento = df_result02.groupby('UNIT')[['VALUE', 'VALUE_ID']].mean()\n",
        "print(\"\\nMédias de VALUE e VALUE_ID por UNIT:\")\n",
        "print(agrupamento)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='VALUE_ID', y='VALUE', hue='UNIT', data=df_result02)\n",
        "plt.title('Relação entre VALUE_ID e VALUE colorido por UNIT')\n",
        "plt.xlabel('VALUE_ID')\n",
        "plt.ylabel('VALUE')\n",
        "plt.legend(title='UNIT', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converter 'VALUE' e 'VALUE_ID' para numérico\n",
        "df_result02['VALUE'] = pd.to_numeric(df_result02['VALUE'], errors='coerce')\n",
        "df_result02['VALUE_ID'] = pd.to_numeric(df_result02['VALUE_ID'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remover linhas com valores nulos em 'VALUE' ou 'VALUE_ID'\n",
        "df_result02 = df_result02.dropna(subset=['VALUE', 'VALUE_ID'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_unique_value = df_result02['VALUE'].nunique()\n",
        "num_unique_value_id = df_result02['VALUE_ID'].nunique()\n",
        "\n",
        "print(f\"Número de valores únicos em 'VALUE': {num_unique_value}\")\n",
        "print(f\"Número de valores únicos em 'VALUE_ID': {num_unique_value_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ajustar 'q' com base no número de valores únicos\n",
        "q_value = min(4, num_unique_value)\n",
        "q_value_id = min(4, num_unique_value_id)\n",
        "\n",
        "# Categorizar 'VALUE'\n",
        "df_result02['VALUE_cat'] = pd.qcut(df_result02['VALUE'], q=q_value, labels=False, duplicates='drop')\n",
        "\n",
        "# Categorizar 'VALUE_ID'\n",
        "df_result02['VALUE_ID_cat'] = pd.qcut(df_result02['VALUE_ID'], q=q_value_id, labels=False, duplicates='drop')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_result02['VALUE_cat'].isnull().sum())\n",
        "print(df_result02['VALUE_ID_cat'].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Criar a matriz de confusão\n",
        "conf_mat = confusion_matrix(df_result02['VALUE_ID_cat'], df_result02['VALUE_cat'])\n",
        "\n",
        "# Exibir a matriz de confusão\n",
        "print(\"\\nMatriz de Confusão entre VALUE_ID_cat e VALUE_cat:\")\n",
        "print(conf_mat)\n",
        "\n",
        "# Visualizar a matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Q1', 'Q2', 'Q3', 'Q4'],\n",
        "            yticklabels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
        "plt.xlabel('VALUE_cat')\n",
        "plt.ylabel('VALUE_ID_cat')\n",
        "plt.title('Matriz de Confusão entre VALUE_ID_cat e VALUE_cat')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Codificar 'UNIT' numericamente\n",
        "df_result02['UNIT_code'] = df_result02['UNIT'].astype('category').cat.codes\n",
        "\n",
        "conf_mat_unit = confusion_matrix(df_result02['UNIT_code'], df_result02['VALUE_cat'])\n",
        "\n",
        "unit_labels = df_result02['UNIT'].astype('category').cat.categories\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(conf_mat_unit, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Q1', 'Q2', 'Q3', 'Q4'],\n",
        "            yticklabels=unit_labels)\n",
        "plt.xlabel('VALUE_cat')\n",
        "plt.ylabel('UNIT')\n",
        "plt.title('Matriz de Confusão entre UNIT e VALUE_cat')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploração dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = pd.read_excel('RESULTADOS_02_03_2024.xlsx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.columns\n",
        "df_result02.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.columns = df_result02.iloc[0]\n",
        "df_result02 = df_result02[1:]\n",
        "df_result02.columns = df_result02.columns.astype(str)\n",
        "df_result02 = df_result02.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = df_result02.loc[:, df_result02.columns != 'nan']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "unique_names = df_result02['NAME'].unique()\n",
        "\n",
        "print(\"Valores únicos na coluna 'NAME':\")\n",
        "print(unique_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_unique_names = df_result02['NAME'].nunique()\n",
        "print(f\"Número de valores únicos na coluna 'NAME': {num_unique_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_value_ids = df_result02['VALUE_ID'].unique()\n",
        "\n",
        "print(\"Valores únicos na coluna 'VALUE_ID':\")\n",
        "print(unique_value_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_unique_value_ids = df_result02['VALUE_ID'].nunique()\n",
        "print(f\"Número de valores únicos na coluna 'VALUE_ID': {num_unique_value_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_null_names = df_result02['NAME'].isnull().sum()\n",
        "print(f\"Número de valores nulos na coluna 'NAME': {num_null_names}\")\n",
        "\n",
        "\n",
        "num_null_value_ids = df_result02['VALUE_ID'].isnull().sum()\n",
        "print(f\"Número de valores nulos na coluna 'VALUE_ID': {num_null_value_ids}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result02 = df_result02.dropna(subset=['VALUE_ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_names_sorted = sorted(unique_names)\n",
        "unique_value_ids_sorted = sorted(unique_value_ids)\n",
        "\n",
        "print(\"Valores únicos na coluna 'NAME' (ordenados):\")\n",
        "print(unique_names_sorted)\n",
        "\n",
        "print(\"Valores únicos na coluna 'VALUE_ID' (ordenados):\")\n",
        "print(unique_value_ids_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupar por 'NAME' e 'VALUE_ID' e contar as ocorrências\n",
        "contagens_name_valueid = df_result02.groupby(['NAME', 'VALUE_ID']).size().reset_index(name='counts')\n",
        "\n",
        "# Exibir as contagens\n",
        "print(contagens_name_valueid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar as combinações onde counts > 1\n",
        "combinacoes_repetidas = contagens_name_valueid[contagens_name_valueid['counts'] > 1]\n",
        "\n",
        "# Exibir as combinações repetidas\n",
        "print(\"Combinações repetidas de 'NAME' e 'VALUE_ID':\")\n",
        "print(combinacoes_repetidas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ordenar as combinações por 'counts' em ordem decrescente\n",
        "contagens_ordenadas = contagens_name_valueid.sort_values(by='counts', ascending=False)\n",
        "\n",
        "print(\"Todas as combinações de 'NAME' e 'VALUE_ID' ordenadas por contagem:\")\n",
        "print(contagens_ordenadas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar a tabela dinâmica\n",
        "tabela_pivot = contagens_name_valueid.pivot(index='NAME', columns='VALUE_ID', values='counts').fillna(0)\n",
        "\n",
        "# Exibir a tabela\n",
        "print(tabela_pivot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar o número de 'VALUE_ID's únicos para cada 'NAME'\n",
        "contagem_valueid_por_name = df_result02.groupby('NAME')['VALUE_ID'].nunique().reset_index(name='unique_valueid_count')\n",
        "\n",
        "# Filtrar os 'NAME's que têm mais de um 'VALUE_ID' único\n",
        "names_multiplos_valueid = contagem_valueid_por_name[contagem_valueid_por_name['unique_valueid_count'] > 1]\n",
        "\n",
        "print(\"Nomes associados a múltiplos 'VALUE_ID's:\")\n",
        "print(names_multiplos_valueid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar o número de 'NAME's únicos para cada 'VALUE_ID'\n",
        "contagem_name_por_valueid = df_result02.groupby('VALUE_ID')['NAME'].nunique().reset_index(name='unique_name_count')\n",
        "\n",
        "# Filtrar os 'VALUE_ID's que têm mais de um 'NAME' único\n",
        "valueid_multiplos_names = contagem_name_por_valueid[contagem_name_por_valueid['unique_name_count'] > 1]\n",
        "\n",
        "print(\"VALUE_ID's associados a múltiplos 'NAME's:\")\n",
        "print(valueid_multiplos_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupar por 'NAME' e 'VALUE_ID' e contar as ocorrências\n",
        "contagens_name_valueid = df_result02.groupby(['NAME', 'VALUE_ID']).size().reset_index(name='Counts')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ordenar a tabela por 'Counts' em ordem decrescente\n",
        "contagens_name_valueid_sorted = contagens_name_valueid.sort_values(by='Counts', ascending=False)\n",
        "\n",
        "# Exibir a tabela ordenada\n",
        "print(\"Tabela Ordenada de Contagens para 'NAME' e 'VALUE_ID':\")\n",
        "print(contagens_name_valueid_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar a tabela dinâmica\n",
        "pivot_table = contagens_name_valueid.pivot(index='NAME', columns='VALUE_ID', values='Counts').fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Inicializar os codificadores de labels\n",
        "le_name = LabelEncoder()\n",
        "le_value_id = LabelEncoder()\n",
        "\n",
        "# Ajustar e transformar as colunas\n",
        "df_result02['NAME_encoded'] = le_name.fit_transform(df_result02['NAME'])\n",
        "df_result02['VALUE_ID_encoded'] = le_value_id.fit_transform(df_result02['VALUE_ID'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "conf_matrix = confusion_matrix(df_result02['NAME_encoded'], df_result02['VALUE_ID_encoded'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecionar os top N 'NAME's mais frequentes\n",
        "top_n_names = df_result02['NAME'].value_counts().nlargest(10).index\n",
        "df_top = df_result02[df_result02['NAME'].isin(top_n_names)]\n",
        "\n",
        "# Repetir o processo de codificação e plotagem com df_top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extração de Features \n",
        "## Name e Value_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mO kernel não pôde ser iniciado porque \"TypeAliasType\" não pôde ser importado de \"/home/linguica/.venv/lib/python3.10/site-packages/typing_extensions.py\".\n",
            "\u001b[1;31mClique <a href=\"https://aka.ms/kernelFailuresModuleImportErrFromFile\">aqui</a> para obter mais informações."
          ]
        }
      ],
      "source": [
        "# Exibir os primeiros valores de 'NAME'\n",
        "print(df_result02['NAME'].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir 'NAME' em partes\n",
        "df_result02[['PART1', 'PART2', 'PART3']] = df_result02['NAME'].str.split('_', expand=True)\n",
        "\n",
        "# Exibir as novas colunas\n",
        "print(df_result02[['NAME', 'PART1', 'PART2', 'PART3']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converter 'PART3' para numérico\n",
        "df_result02['PART3_num'] = pd.to_numeric(df_result02['PART3'], errors='coerce')\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['PART3', 'PART3_num']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-Hot Encoding para 'PART1' e 'PART2'\n",
        "df_encoded = pd.get_dummies(df_result02, columns=['PART1', 'PART2'])\n",
        "\n",
        "# Exibir as novas colunas\n",
        "print(df_encoded.filter(regex='PART1_|PART2_').head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Inicializar o codificador\n",
        "le_part1 = LabelEncoder()\n",
        "le_part2 = LabelEncoder()\n",
        "\n",
        "# Codificar as colunas\n",
        "df_result02['PART1_encoded'] = le_part1.fit_transform(df_result02['PART1'])\n",
        "df_result02['PART2_encoded'] = le_part2.fit_transform(df_result02['PART2'])\n",
        "\n",
        "# Exibir as novas colunas\n",
        "print(df_result02[['PART1', 'PART1_encoded', 'PART2', 'PART2_encoded']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exibir valores únicos em 'VALUE_ID'\n",
        "print(df_result02['VALUE_ID'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Normalização\n",
        "scaler_minmax = MinMaxScaler()\n",
        "df_result02['VALUE_ID_norm'] = scaler_minmax.fit_transform(df_result02[['VALUE_ID']])\n",
        "\n",
        "# Padronização\n",
        "scaler_standard = StandardScaler()\n",
        "df_result02['VALUE_ID_std'] = scaler_standard.fit_transform(df_result02[['VALUE_ID']])\n",
        "\n",
        "# Exibir as novas colunas\n",
        "print(df_result02[['VALUE_ID', 'VALUE_ID_norm', 'VALUE_ID_std']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar categorias usando pd.cut\n",
        "df_result02['VALUE_ID_cat'] = pd.cut(df_result02['VALUE_ID'], bins=4, labels=False)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['VALUE_ID', 'VALUE_ID_cat']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar uma nova coluna combinando 'NAME' e 'VALUE_ID'\n",
        "df_result02['NAME_VALUEID'] = df_result02['NAME'] + '_' + df_result02['VALUE_ID'].astype(str)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['NAME', 'VALUE_ID', 'NAME_VALUEID']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "le_name_valueid = LabelEncoder()\n",
        "df_result02['NAME_VALUEID_encoded'] = le_name_valueid.fit_transform(df_result02['NAME_VALUEID'])\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['NAME_VALUEID', 'NAME_VALUEID_encoded']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converter 'DATA' para datetime\n",
        "df_result02['DATA'] = pd.to_datetime(df_result02['DATA'], errors='coerce')\n",
        "\n",
        "# Exibir a coluna convertida\n",
        "print(df_result02['DATA'].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extrair ano, mês, dia, hora, dia da semana\n",
        "df_result02['ANO'] = df_result02['DATA'].dt.year\n",
        "df_result02['MES'] = df_result02['DATA'].dt.month\n",
        "df_result02['DIA'] = df_result02['DATA'].dt.day\n",
        "df_result02['HORA'] = df_result02['DATA'].dt.hour\n",
        "df_result02['DIA_SEMANA'] = df_result02['DATA'].dt.dayofweek  # 0 = segunda-feira\n",
        "\n",
        "# Exibir as novas colunas\n",
        "print(df_result02[['DATA', 'ANO', 'MES', 'DIA', 'HORA', 'DIA_SEMANA']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar frequência de cada 'NAME'\n",
        "name_counts = df_result02['NAME'].value_counts()\n",
        "\n",
        "# Mapear a frequência para o DataFrame\n",
        "df_result02['NAME_freq'] = df_result02['NAME'].map(name_counts)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['NAME', 'NAME_freq']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar frequência de cada 'VALUE_ID'\n",
        "valueid_counts = df_result02['VALUE_ID'].value_counts()\n",
        "\n",
        "# Mapear a frequência para o DataFrame\n",
        "df_result02['VALUE_ID_freq'] = df_result02['VALUE_ID'].map(valueid_counts)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['VALUE_ID', 'VALUE_ID_freq']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir um limiar (por exemplo, média de 'VALUE_ID')\n",
        "limiar = df_result02['VALUE_ID'].mean()\n",
        "\n",
        "# Criar a feature binária\n",
        "df_result02['VALUE_ID_high'] = df_result02['VALUE_ID'].apply(lambda x: 1 if x > limiar else 0)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['VALUE_ID', 'VALUE_ID_high']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular a média de 'VALUE_ID' para cada 'NAME'\n",
        "name_target_mean = df_result02.groupby('NAME')['VALUE_ID'].mean()\n",
        "\n",
        "# Mapear a média para o DataFrame\n",
        "df_result02['NAME_target_mean'] = df_result02['NAME'].map(name_target_mean)\n",
        "\n",
        "# Exibir a nova coluna\n",
        "print(df_result02[['NAME', 'NAME_target_mean']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar valores nulos\n",
        "print(\"Valores nulos por coluna:\")\n",
        "print(df_result02.isnull().sum())\n",
        "\n",
        "# Opcional: Preencher valores nulos ou remover linhas com nulos\n",
        "df_result02 = df_result02.dropna()  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Passo 1: Agrupar por 'NAME' e 'VALUE_ID' e contar ocorrências\n",
        "name_valueid_counts = df_result02.groupby(['NAME', 'VALUE_ID']).size().reset_index(name='Counts')\n",
        "\n",
        "# Passo 2: Identificar combinações repetidas\n",
        "repeating_combinations = name_valueid_counts[name_valueid_counts['Counts'] > 1]\n",
        "\n",
        "# Passo 3: Mesclar com informações de 'KNR'\n",
        "repeating_combinations_knr = pd.merge(repeating_combinations, df_result02[['NAME', 'VALUE_ID', 'KNR']], on=['NAME', 'VALUE_ID'], how='left')\n",
        "\n",
        "# Passo 4: Remover duplicatas\n",
        "repeating_combinations_knr = repeating_combinations_knr.drop_duplicates(subset=['NAME', 'VALUE_ID', 'KNR'])\n",
        "\n",
        "# Passo 5: Criar mapeamento com o 'KNR' mais frequente\n",
        "most_frequent_knr = df_result02.groupby(['NAME', 'VALUE_ID'])['KNR'].agg(lambda x: x.value_counts().index[0]).reset_index()\n",
        "name_valueid_to_knr = most_frequent_knr.set_index(['NAME', 'VALUE_ID'])['KNR'].to_dict()\n",
        "\n",
        "# Passo 6: Adicionar nova coluna ao DataFrame\n",
        "df_result02['KNR_associated'] = df_result02.apply(lambda row: name_valueid_to_knr.get((row['NAME'], row['VALUE_ID']), None), axis=1)\n",
        "\n",
        "# Passo 7: Verificar os resultados\n",
        "df_result02['KNR_match'] = df_result02['KNR'] == df_result02['KNR_associated']\n",
        "discrepancies = df_result02[df_result02['KNR_match'] == False]\n",
        "\n",
        "# Exibir o DataFrame final\n",
        "print(df_result02[['NAME', 'VALUE_ID', 'KNR', 'KNR_associated', 'KNR_match']])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
